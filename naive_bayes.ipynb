{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "naive-bayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNv4YsHVqL/cJF6rXAh02B0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuFernandez/neural-networks/blob/master/naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEtsMMbZ7huw",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes\n",
        "## Redes Neuronales\n",
        "\n",
        "© 2020 Lucero G. Fernandez\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Mq_BY17kXO",
        "colab_type": "code",
        "outputId": "8c71bf0a-35ab-432c-f5ca-9c795c8d74a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN80P6KV7lfz",
        "colab_type": "text"
      },
      "source": [
        "### Carga de datos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tabqc_l7qti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget \"https://raw.githubusercontent.com/rn-2019-itba/Clase-2--Hiperparametros-y-Tecnicas-de-Validacion/master/Opcional/data/emails.csv\"\n",
        "clear_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCHha6as8SHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('emails.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1cHKozu8l9B",
        "colab_type": "code",
        "outputId": "3aa6247f-671a-4380-99da-5c2066cdffd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'spam'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r82mfvzADL2h",
        "colab_type": "code",
        "outputId": "ad1c7e4a-90c0-4081-cdea-dfd2d94b178e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.spam[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCWxp3UCDh5k",
        "colab_type": "code",
        "outputId": "3d3de95e-6afb-47fa-8569-525bf5225155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "dataset['spam']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       1\n",
              "2       1\n",
              "3       1\n",
              "4       1\n",
              "       ..\n",
              "5723    0\n",
              "5724    0\n",
              "5725    0\n",
              "5726    0\n",
              "5727    0\n",
              "Name: spam, Length: 5728, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmYkOz9xBtDu",
        "colab_type": "text"
      },
      "source": [
        "Se tienen 5728 emails de dos tipos: text y spam. En text están las palabras y en spam si es o no spam (1==spam)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdBGMi9jBYzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in range(len(dataset['spam'])):\n",
        "#  if dataset.spam[i]==1:\n",
        " #   print(dataset.spam[i])\n",
        "\n",
        " #la cantidad de emails que son spam\n",
        " spam_count=np.sum(dataset.spam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kgmprQMA6On",
        "colab_type": "text"
      },
      "source": [
        "Probabilidad a priori de que sea spam:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCzpggpI8tx_",
        "colab_type": "code",
        "outputId": "9daf3de3-9359-4820-d180-f35a4363277a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(spam_count/len(dataset)*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23.88268156424581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoYBRPT2EmqL",
        "colab_type": "text"
      },
      "source": [
        "#  Preprocesamos los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSMdehKv8t0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Soerxo58t3k",
        "colab_type": "code",
        "outputId": "16589019-c181-4362-c5ed-538ee8f1a582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('stopwords')\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOPty9tb8t5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emails_raw=dataset.text\n",
        "emails_filtered=list()\n",
        "\n",
        "for n in range(len(dataset)):\n",
        "  tok = word_tokenize(emails_raw[n])  #tokenization\n",
        "  lem = [lemmatizer.lemmatize(x,pos = 'v') for x in tok] #lemmatization\n",
        "  stop = [x for x in lem if x not in stopwords.words('english')] #stop words\n",
        "  stem = [stemmer.stem(x) for x in stop] #stemming\n",
        "  alpha = [x for x in stem if x.isalpha()]  #filter non words\n",
        "\n",
        "  emails_filtered.append(\" \".join(alpha))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4BmI_cnfJ0x",
        "colab_type": "text"
      },
      "source": [
        "Guardo en disco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE29zgnz8t8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('em_filt.pck', 'wb') as fp:\n",
        "    pickle.dump(emails_filtered, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH-yEv5y8t_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open ('em_filt.pck', 'rb') as fp:\n",
        "    itemlist = pickle.load(fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLaXmjopiYhM",
        "colab_type": "text"
      },
      "source": [
        "Bag of Words\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4AQMsNuial6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Count Vectorizer\n",
        "\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# count_vect = CountVectorizer(max_df=.8,min_df=10)\n",
        "# raw_data=count_vect.fit_transform(emails_filtered)\n",
        "# raw_data.toarray()\n",
        "\n",
        "\n",
        "#TfidVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vect = TfidfVectorizer(max_df=0.8,min_df=10)\n",
        "raw_data = tfidf_vect.fit_transform(itemlist)\n",
        "vocabulary=tfidf_vect.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF9EymEspq-Z",
        "colab_type": "text"
      },
      "source": [
        "##Entreno modelo de Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnepBacapxUr",
        "colab_type": "text"
      },
      "source": [
        "creo set de datos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtwrNrAypqAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_train = int(raw_data.shape[0]*0.83)\n",
        "X_train = raw_data[0:len_train]\n",
        "y_train = dataset[0:len_train]['spam']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_hdurxKqdLy",
        "colab_type": "text"
      },
      "source": [
        "creo set de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G71JSu09qek8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len_test = raw_data.shape[0]-len_train   #lo que no es train es test\n",
        "X_test = raw_data[len_test:]\n",
        "y_test = dataset[len_test:]['spam']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRsx8OH-rFeN",
        "colab_type": "text"
      },
      "source": [
        "entreno modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nApbTaEvrGy0",
        "colab_type": "code",
        "outputId": "2b82cc98-1633-4d27-b1f5-c4fc9b41d76c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB(alpha=.01)\n",
        "clf.fit(X_train.toarray(), y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is9YEs5vt13T",
        "colab_type": "text"
      },
      "source": [
        "Analizo la precisión del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXQHvWutrl8L",
        "colab_type": "code",
        "outputId": "8ad03b30-9cac-4bf3-ba19-0ddabe0d0aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "porc=sum(np.array(clf.predict(X_test.toarray()))==np.array(y_test))/len(y_test)*100\n",
        "f'El porcentaje de emails clasificados correctamente es: {porc}%'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El porcentaje de emails clasificados correctamente es: 99.76861590239798%'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 392
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlFAsd3wt6cq",
        "colab_type": "text"
      },
      "source": [
        "Se probó con un alpha = 1, con el que se obtuvo una precisión de 99.32%, pero se obtuvieron mejores resultados con un smoothing menor, seteado a 0.01, lo que dio una precisión del 99.67%.\n",
        "Además se probó tanto count vectorizer como tfid vectorizer siendo el último el que dio mejores resultados.\n",
        "La precisión también aumentó cuando se incrementaron los datos usados para testear y se disminuyeron la cantidad para entrenar al modelo y a su vez también, al disminuir la mínima frecuencia de aparición de cada palabra del vocabulario, esto es, min_df."
      ]
    }
  ]
}